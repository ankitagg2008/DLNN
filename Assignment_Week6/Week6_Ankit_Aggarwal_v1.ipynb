{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc1cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier # using 1NN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm \n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94270242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0c625d",
   "metadata": {},
   "source": [
    "### (1). Create a train data loader that returns image arrays and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(train_dirs):\n",
    "    # Initialize empty lists for to store image arrays and labels\n",
    "    image_arrays = []\n",
    "    image_labels = []\n",
    "   \n",
    "    # loop to navitage all directories and read information from all the image files\n",
    "    for label, directory in enumerate(sorted(os.listdir(train_dirs))):\n",
    "        path = os.path.join(train_dirs, directory)\n",
    "\n",
    "        # check if it's a directory\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "\n",
    "        # Iterate over image files in the directory\n",
    "        for img_file in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "\n",
    "            # resize and store images\n",
    "            img = cv2.resize(plt.imread(img_path).copy(), (224, 224))\n",
    "            image_labels.append(label)\n",
    "            image_arrays.append(img)\n",
    "            \n",
    "    return image_arrays, image_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c75bdb",
   "metadata": {},
   "source": [
    "### (2). Create a test data loader that returns image arrays and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541e9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader(data_dir):\n",
    "    # Get a list of image files in the test data directory\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    # Initialize lists for data and file names\n",
    "    image_arrays = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Iterate over the image files\n",
    "    for file in image_files:\n",
    "        # Get the full path of the image\n",
    "        path = os.path.join(data_dir, file)\n",
    "        \n",
    "        # Read and preprocess the image\n",
    "        img = cv2.resize(plt.imread(path).copy(), (224, 224))\n",
    "        #img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Append the preprocessed image and file name to the lists\n",
    "        image_arrays.append(img)\n",
    "        image_names.append(file)\n",
    "    \n",
    "    # Convert lists to NumPy arrays and return\n",
    "    return image_arrays, image_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad569b2",
   "metadata": {},
   "source": [
    "### (3). Print image arrays, labels and file names dimensions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09431a",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c273b98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Array: (1149, 224, 224, 3)\n",
      "Training Label Shape: (1149,)\n"
     ]
    }
   ],
   "source": [
    "train_loader = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Training'\n",
    "training_array, training_labels = train_data_loader(train_loader)\n",
    "training_array, training_labels = np.array(training_array), np.array(training_labels)\n",
    "\n",
    "print(\"Training Dataset Array:\",training_array.shape )\n",
    "print(\"Training Label Shape:\",training_labels.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f15e42",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "   - The training dataset contains total 1149 images of size 224, 224 and has 3 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b0d89",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6530b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Array: (380, 224, 224, 3)\n",
      "Test File Names Extracted: (380,)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "test_loader=r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Test_Data'\n",
    "test_array, test_file_name = test_data_loader(test_loader)\n",
    "test_array, test_file_name = np.array(test_array), np.array(test_file_name)\n",
    "\n",
    "print(\"Test Dataset Array:\",test_array.shape )\n",
    "print(\"Test File Names Extracted:\",test_file_name.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afa108",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "   - The test dataset contains total 380 images of size 224, 224 and has 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3068c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629f0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4520e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da763355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e8fc2",
   "metadata": {},
   "source": [
    "# 1. Build your own neural network with 3 hidden layers using pytorch (60 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133be475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c45b84",
   "metadata": {},
   "source": [
    "# 2. Train your model using cow teat datasets (30 points)\n",
    "\n",
    "## You can resize the image to 75 * 75 *3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50effdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f63262f",
   "metadata": {},
   "source": [
    "# 3. Evaluate your model using the developed software (10 points)\n",
    "## Grading Rubric:\n",
    "## (1). > = 50% -->10 points\n",
    "## (2). < 30 % -->0 points\n",
    "## (2). >= 30 % & < 50% -->0.5 point/percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687038bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
