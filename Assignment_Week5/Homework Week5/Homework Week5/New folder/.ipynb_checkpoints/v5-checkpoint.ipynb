{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0663e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier # using 1NN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm \n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927e50a",
   "metadata": {},
   "source": [
    "# 1. Download the [cow teat datasets](https://github.com/YoushanZhang/SCTL) (10 points) resize image to (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(train_dirs):\n",
    "    # Initialize empty lists for to store image arrays and labels\n",
    "    image_arrays = []\n",
    "    image_labels = []\n",
    "   \n",
    "    # loop to navitage all directories and read information from all the image files\n",
    "    for label, directory in enumerate(sorted(os.listdir(train_dirs))):\n",
    "        path = os.path.join(train_dirs, directory)\n",
    "\n",
    "        # check if it's a directory\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "\n",
    "        # Iterate over image files in the directory\n",
    "        for img_file in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "\n",
    "            # resize and store images\n",
    "            img = cv2.resize(plt.imread(img_path).copy(), (224, 224))\n",
    "            image_labels.append(label)\n",
    "            image_arrays.append(img)\n",
    "            \n",
    "    return image_arrays, image_labels\n",
    "\n",
    "\n",
    "def test_data_loader(data_dir):\n",
    "    # Get a list of image files in the test data directory\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    # Initialize lists for data and file names\n",
    "    image_arrays = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Iterate over the image files\n",
    "    for file in image_files:\n",
    "        # Get the full path of the image\n",
    "        path = os.path.join(data_dir, file)\n",
    "        \n",
    "        # Read and preprocess the image\n",
    "        img = cv2.resize(plt.imread(path).copy(), (224, 224))\n",
    "        #img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Append the preprocessed image and file name to the lists\n",
    "        image_arrays.append(img)\n",
    "        image_names.append(file)\n",
    "    \n",
    "    # Convert lists to NumPy arrays and return\n",
    "    return image_arrays, image_names\n",
    "\n",
    "train_loader = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Training'\n",
    "training_array, training_labels = train_data_loader(train_loader)\n",
    "training_array, training_labels = np.array(training_array), np.array(training_labels)\n",
    "\n",
    "test_loader=r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Test_Data'\n",
    "test_array, test_file_name = test_data_loader(test_loader)\n",
    "test_array, test_file_name = np.array(test_array), np.array(test_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c625d",
   "metadata": {},
   "source": [
    "### (1). Create a train data loader that returns image arrays and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b0b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(train_dirs):\n",
    "    # Initialize empty lists for to store image arrays and labels\n",
    "    image_arrays = []\n",
    "    image_labels = []\n",
    "   \n",
    "    # loop to navitage all directories and read information from all the image files\n",
    "    for label, directory in enumerate(sorted(os.listdir(train_dirs))):\n",
    "        path = os.path.join(train_dirs, directory)\n",
    "\n",
    "        # check if it's a directory\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "\n",
    "        # Iterate over image files in the directory\n",
    "        for img_file in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "\n",
    "            # resize and store images\n",
    "            img = cv2.resize(plt.imread(img_path).copy(), (224, 224))\n",
    "            image_labels.append(label)\n",
    "            image_arrays.append(img)\n",
    "            \n",
    "    return image_arrays, image_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c75bdb",
   "metadata": {},
   "source": [
    "### (2). Create a test data loader that returns image arrays and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541e9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader(data_dir):\n",
    "    # Get a list of image files in the test data directory\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    # Initialize lists for data and file names\n",
    "    image_arrays = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Iterate over the image files\n",
    "    for file in image_files:\n",
    "        # Get the full path of the image\n",
    "        path = os.path.join(data_dir, file)\n",
    "        \n",
    "        # Read and preprocess the image\n",
    "        img = cv2.resize(plt.imread(path).copy(), (224, 224))\n",
    "        #img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Append the preprocessed image and file name to the lists\n",
    "        image_arrays.append(img)\n",
    "        image_names.append(file)\n",
    "    \n",
    "    # Convert lists to NumPy arrays and return\n",
    "    return image_arrays, image_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad569b2",
   "metadata": {},
   "source": [
    "### (3). Print image arrays, labels and file names dimensions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09431a",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c273b98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Array: (1149, 224, 224, 3)\n",
      "Training Label Shape: (1149,)\n"
     ]
    }
   ],
   "source": [
    "train_loader = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Training'\n",
    "training_array, training_labels = train_data_loader(train_loader)\n",
    "training_array, training_labels = np.array(training_array), np.array(training_labels)\n",
    "\n",
    "print(\"Training Dataset Array:\",training_array.shape )\n",
    "print(\"Training Label Shape:\",training_labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbccb478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f15e42",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "   - The training dataset contains total 1149 images of size 224, 224 and has 3 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b0d89",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6530b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Array: (380, 224, 224, 3)\n",
      "Test File Names Extracted: (380,)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "test_loader=r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Test_Data'\n",
    "test_array, test_file_name = test_data_loader(test_loader)\n",
    "test_array, test_file_name = np.array(test_array), np.array(test_file_name)\n",
    "\n",
    "print(\"Test Dataset Array:\",test_array.shape )\n",
    "print(\"Test File Names Extracted:\",test_file_name.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afa108",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "   - The test dataset contains total 380 images of size 224, 224 and has 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e6eb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 3)  # Replace 'num_classes' with the number of classes in your dataset\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b4ba915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function (e.g., CrossEntropy for classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (e.g., Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5b985eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.44 GiB (GPU 0; 8.00 GiB total capacity; 18.43 GiB already allocated; 0 bytes free; 20.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-2c88bb0b58a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dlnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-c40908dfdcfd>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dlnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dlnn\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dlnn\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.44 GiB (GPU 0; 8.00 GiB total capacity; 18.43 GiB already allocated; 0 bytes free; 20.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded your training data into 'training_array' and 'training_labels'\n",
    "\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "training_data = torch.Tensor(training_array)\n",
    "training_labels = torch.LongTensor(training_labels)\n",
    "\n",
    "# Define the number of classes (replace with the actual number)\n",
    "num_classes = 10  # Change to your actual number of classes\n",
    "\n",
    "# Initialize your neural network\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Set the device (CPU or GPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "\n",
    "# Assuming 'training_data' has shape [1149, 224, 224, 3]\n",
    "# You can permute the dimensions to match the expected shape [1149, 3, 224, 224]\n",
    "training_data = training_data.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # You can adjust this as needed\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(training_data.to(device))\n",
    "    loss = criterion(outputs, training_labels.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b97bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
