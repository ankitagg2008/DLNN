{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier # using 1NN\n",
    "import re\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927e50a",
   "metadata": {},
   "source": [
    "# 1. Download the [cow teat datasets](https://github.com/YoushanZhang/SCTL) (10 points) resize image to (224, 224)\n",
    "\n",
    "### (1). Create a train data loader that returns image arrays and labels\n",
    "### (2). Create a test data loader that returns image arrays and file names\n",
    "### (3). Print image arrays, labels and file names dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26578c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        # Traverse the directory structure to load images and assign labels\n",
    "        for train_folder in os.listdir(root_dir):\n",
    "            train_folder_path = os.path.join(root_dir, train_folder)\n",
    "            if os.path.isdir(train_folder_path):\n",
    "                for score_folder in os.listdir(train_folder_path):\n",
    "                    score_folder_path = os.path.join(train_folder_path, score_folder)\n",
    "                    if os.path.isdir(score_folder_path):\n",
    "                        for image_file in os.listdir(score_folder_path):\n",
    "                            if image_file.endswith(\".jpg\"):  # Assuming images are in JPG format\n",
    "                                image_path = os.path.join(score_folder_path, image_file)\n",
    "                                self.data.append(image_path)\n",
    "                                self.labels.append(int(train_folder.split(\"_\")[1]))  # Extract label from folder name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.data[idx])\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Define your data loader\n",
    "root_folder = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Training'\n",
    "train_dataset = CustomDataset(root_folder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# You can use train_loader to iterate through your dataset in batches\n",
    "for images, labels in train_loader:\n",
    "    # Your training code here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52052845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the root directory where your data is stored\n",
    "root_dir = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Training'\n",
    "\n",
    "# Define a transformation to apply to the images (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to a fixed size\n",
    "    transforms.ToTensor()#,           # Convert the image to a tensor\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Create a dataset using ImageFolder\n",
    "dataset = ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "# If you have a GPU, you can use it for faster training\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a function to extract the numerical part from a string\n",
    "def extract_numerical_part(s):\n",
    "    # Use regular expressions to extract the numerical part of the string\n",
    "    match = re.search(r'\\d+', s)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a data loader for the dataset\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Initialize lists to store data\n",
    "image_names = []\n",
    "image_sizes = []\n",
    "labels = []\n",
    "\n",
    "# Prepare data with Image Name, Size, and Label\n",
    "for index, (images, batch_labels) in enumerate(data_loader):\n",
    "    # Iterate through each batch of images and labels\n",
    "    for i in range(len(images)):\n",
    "        image_name = os.path.basename(dataset.imgs[index * 32 + i][0])\n",
    "        image_size = images[i].shape\n",
    "        subfolder_name = os.path.basename(os.path.dirname(dataset.imgs[index * 32 + i][0]))\n",
    "        numerical_label = extract_numerical_part(subfolder_name)\n",
    "        if numerical_label is not None:\n",
    "            image_names.append(image_name)\n",
    "            image_sizes.append(image_size)\n",
    "            labels.append(numerical_label)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'Image Name': image_names, 'Size': image_sizes, 'Label': labels})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5ec7c",
   "metadata": {},
   "source": [
    "# 2. Extract features of training and test images using HOG (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1149 * d, test features: 380 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4ac0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5339f5",
   "metadata": {},
   "source": [
    "# 3. Extract features of training and test images using SIFT (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1149 * d, test features: 380 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f0084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753188e2",
   "metadata": {},
   "source": [
    "# 4. Extract features of training and test images using SURF (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1149 * d, test features: 380 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554f280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0e3e068",
   "metadata": {},
   "source": [
    "# 5. Call SVM and kNN from scikit-learn and train the extracted HOG, SIFT and SURF features, respectively, save three CSV files of test dataset using three features (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68704a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd101cf",
   "metadata": {},
   "source": [
    "# 6. Report the accuracy using Cow_teat_classfication_accuracy software, please attach the results image here (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea49db",
   "metadata": {},
   "source": [
    "### (1). SVM and 1NN using HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecc816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1163e551",
   "metadata": {},
   "source": [
    "### (2). SVM and 1NN using SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a54656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2908c75a",
   "metadata": {},
   "source": [
    "### (3). SVM and 1NN using SURF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fb829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
