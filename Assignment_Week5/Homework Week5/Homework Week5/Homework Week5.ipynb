{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0663e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier # using 1NN\n",
    "import re\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import requests\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d81aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# If you have a GPU, you can use it for faster training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927e50a",
   "metadata": {},
   "source": [
    "# 1. Download the [cow teat datasets](https://github.com/YoushanZhang/SCTL) (10 points) resize image to (224, 224)\n",
    "\n",
    "### (1). Create a train data loader that returns image arrays and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766b08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the training data images .\n",
    "train_data = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Training'\n",
    "\n",
    "# Defineing a transformation that we need to apply to all the images for example resize to (224, 224). \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to a fixed size\n",
    "    transforms.ToTensor()           # Convert the image to a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598d7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset using ImageFolder\n",
    "dataset = ImageFolder(root=train_data, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e510f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the numerical part from a string\n",
    "def extract_label(s):\n",
    "    '''\n",
    "        This function is used to extract the label of the training image based on the suffix number of Score Folder. \n",
    "        \n",
    "        Input: \n",
    "            S : Folder Name like Score_1, Score_2 etc. \n",
    "        Output: \n",
    "            The numerical part from the folder name like '1', '2' etc. \n",
    "    '''\n",
    "    # Use regular expressions to extract the numerical part of the string\n",
    "    match = re.search(r'\\d+', s)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b54e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data loader for the dataset\n",
    "train_data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2a5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "train_image_arrays = []\n",
    "train_image_names = []\n",
    "train_labels = []\n",
    "\n",
    "# Prepare data with Image Array, Image Name, and Label\n",
    "for index, (images, batch_labels) in enumerate(train_data_loader):\n",
    "    # Iterate through each batch of images and labels\n",
    "    for i in range(len(images)):\n",
    "        image_array = images[i].numpy()  # Convert tensor to NumPy array\n",
    "        image_name = os.path.basename(dataset.imgs[index * 32 + i][0])\n",
    "        subfolder_name = os.path.basename(os.path.dirname(dataset.imgs[index * 32 + i][0]))\n",
    "        numerical_label = extract_label(subfolder_name)\n",
    "        if numerical_label is not None:\n",
    "            train_image_arrays.append(image_array)\n",
    "            train_image_names.append(image_name)\n",
    "            train_labels.append(numerical_label)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_train = pd.DataFrame({'Image Name': train_image_arrays, 'Size': train_image_names, 'Label': train_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c0422",
   "metadata": {},
   "source": [
    "### (2). Create a test data loader that returns image arrays and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d458e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the test data images .\n",
    "test_data = r'C:\\AKA\\Backup Dell Laptop\\D Drive\\YU\\Semester 2\\Neural Network\\DLNN\\Assignment_Week5\\Homework Week5\\Homework Week5\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ad4f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset using ImageFolder\n",
    "test_dataset = ImageFolder(root=test_data, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8ee9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test data loader for the test dataset\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce9850e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "test_image_arrays = []\n",
    "test_image_names = []\n",
    "test_labels = []\n",
    "\n",
    "# Prepare data with Image Array, Image Name, and Label\n",
    "for index, (images, batch_labels) in enumerate(test_data_loader):\n",
    "    # Iterate through each batch of images and labels\n",
    "    for i in range(len(images)):\n",
    "        image_array = images[i].numpy()  # Convert tensor to NumPy array\n",
    "        image_name = os.path.basename(dataset.imgs[index * 32 + i][0])\n",
    "        subfolder_name = os.path.basename(os.path.dirname(dataset.imgs[index * 32 + i][0]))\n",
    "        numerical_label = extract_label(subfolder_name)\n",
    "        if numerical_label is not None:\n",
    "            test_image_arrays.append(image_array)\n",
    "            test_image_names.append(image_name)\n",
    "            test_labels.append(numerical_label)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_test = pd.DataFrame({'Image Name': test_image_names, 'test_image_arrays': test_image_arrays})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77626738",
   "metadata": {},
   "source": [
    "### (3). Print image arrays, labels and file names dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afaa73d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Images: 1149\n",
      "Training Image Array Size: (3, 224, 224)\n",
      "Training Image Labels Size: (1149,)\n"
     ]
    }
   ],
   "source": [
    "# Display Training Data Summary\n",
    "print(f\"Number of Training Images: {len(df_train)}\")\n",
    "print(f\"Training Image Array Size: {train_image_arrays[1].shape}\")  # Assuming all images have the same size\n",
    "print(f\"Training Image Labels Size: {df_train['Label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d55c81a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Images: 380\n",
      "Test Image Array Size: (3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Display Test Image Summary\n",
    "print(f\"Number of Test Images: {len(df_test)}\")\n",
    "print(f\"Test Image Array Size: {test_image_arrays[0].shape}\")  # Assuming all images have the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5ec7c",
   "metadata": {},
   "source": [
    "# 2. Extract features of training and test images using HOG (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1149 * d, test features: 380 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "078a56f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2818090206.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[81], line 34\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f'Failed to download image {i+1}: {image_name}')/\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57f3532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store HOG features\n",
    "train_hog_features = []\n",
    "test_hog_features = []\n",
    "\n",
    "# Iterate through the training data loader\n",
    "for images, _ in train_data_loader:\n",
    "    for img in images:\n",
    "        # Convert PyTorch tensor to NumPy array and convert to grayscale\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Resize the image to (224, 224) as you did before\n",
    "        gray_resized_img = cv2.resize(gray_img, (224, 224))\n",
    "\n",
    "        # Calculate HOG features\n",
    "        features = hog(gray_resized_img, pixels_per_cell=(16, 16), visualize=False)\n",
    "\n",
    "        # Append the features to the list\n",
    "        train_hog_features.append(features)\n",
    "\n",
    "# Iterate through the test data loader\n",
    "for images, _ in test_data_loader:\n",
    "    for img in images:\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        gray_resized_img = cv2.resize(gray_img, (224, 224))\n",
    "        features = hog(gray_resized_img, pixels_per_cell=(16, 16), visualize=False)\n",
    "        test_hog_features.append(features)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "train_hog_features = np.array(train_hog_features)\n",
    "test_hog_features = np.array(test_hog_features)\n",
    "\n",
    "# Now, train_hog_features contains HOG features for training data, and test_hog_features contains HOG features for test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73f93e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 11664)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hog_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32ce4b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 11664)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hog_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HOG parameters\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (3, 3)\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "train_hog_features = []\n",
    "train_hog_labels = []\n",
    "test_hog_features = []\n",
    "test_hog_labels = []\n",
    "\n",
    "# Extract features for training images\n",
    "for i, img in enumerate(train_data):\n",
    "    # Compute HOG descriptors for each image\n",
    "    features = hog(img, orientations=orientations, pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block, transform_sqrt=True, feature_vector=True)\n",
    "    train_hog_features.append(features)\n",
    "    train_hog_labels.append(labels[i])\n",
    "    \n",
    "# Extract features for test images\n",
    "for i, img in enumerate(test_data):\n",
    "    # Compute HOG descriptors for each image\n",
    "    features = hog(img, orientations=orientations, pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block, transform_sqrt=True, feature_vector=True)\n",
    "    test_hog_features.append(features)\n",
    "    test_hog_labels.append(test_file_names[i])\n",
    "\n",
    "# Convert feature lists to numpy arrays\n",
    "train_hog_features = np.array(train_hog_features)\n",
    "test_hog_features = np.array(test_hog_features)\n",
    "\n",
    "# Print the size of extracted features\n",
    "print(f\"Training features: {train_hog_features.shape[0]} * {train_hog_features.shape[1]}\")\n",
    "print(f\"Test features: {test_hog_features.shape[0]} * {test_hog_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5339f5",
   "metadata": {},
   "source": [
    "# 3. Extract features of training and test images using SIFT (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1149 * d, test features: 380 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95181968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f0084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753188e2",
   "metadata": {},
   "source": [
    "# 4. Extract features of training and test images using SURF (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1149 * d, test features: 380 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554f280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0e3e068",
   "metadata": {},
   "source": [
    "# 5. Call SVM and kNN from scikit-learn and train the extracted HOG, SIFT and SURF features, respectively, save three CSV files of test dataset using three features (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68704a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd101cf",
   "metadata": {},
   "source": [
    "# 6. Report the accuracy using Cow_teat_classfication_accuracy software, please attach the results image here (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea49db",
   "metadata": {},
   "source": [
    "### (1). SVM and 1NN using HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5ecc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_hog_features = np.array(train_hog_features)\n",
    "#test_hog_features = np.array(test_hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a6d6a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 11664)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hog_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f486641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\envs\\aka\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:226: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = svm.SVC()\n",
    "\n",
    "# Train the SVM classifier on the training HOG features and labels\n",
    "clf.fit(train_hog_features, train_labels)\n",
    "\n",
    "# Perform predictions on the test HOG features\n",
    "test_predictions = clf.predict(test_hog_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Return the accuracy\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7635025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 380/380 [00:04<00:00, 83.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "HOG predictions saved to CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\aka\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:226: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Score_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Score_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Score_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Score_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Score_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Score_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Score_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Score_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Score_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Score_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0    Score_2\n",
       "1    Score_2\n",
       "2    Score_1\n",
       "3    Score_1\n",
       "4    Score_3\n",
       "..       ...\n",
       "375  Score_2\n",
       "376  Score_3\n",
       "377  Score_2\n",
       "378  Score_2\n",
       "379  Score_2\n",
       "\n",
       "[380 rows x 1 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "# ... (Previous code for HOG feature extraction)\n",
    "\n",
    "# Train SVM classifier on HOG features\n",
    "svmHog = svm.SVC(kernel='linear')\n",
    "svmHog.fit(train_hog_features, train_labels)\n",
    "\n",
    "# Predict using SVM classifier\n",
    "svmHog_preds = []\n",
    "for features in tqdm(test_hog_features):\n",
    "    svmHog_preds.append(svmHog.predict([features]))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, svmHog_preds)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Convert numpy array to dataframe\n",
    "svm_preds_df = pd.DataFrame(svmHog_preds)\n",
    "svm_preds_df = pd.DataFrame(test_file_names, svmSiftPred)\n",
    "\n",
    "# Write predictions to CSV files\n",
    "#svm_preds_df.to_csv(\"csv/hog_test_predictions_svm.csv\")\n",
    "print(\"HOG predictions saved to CSV files\")\n",
    "\n",
    "svm_preds_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163e551",
   "metadata": {},
   "source": [
    "### (2). SVM and 1NN using SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a54656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2908c75a",
   "metadata": {},
   "source": [
    "### (3). SVM and 1NN using SURF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fb829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b0bf0d5",
   "metadata": {},
   "source": [
    "### Citations:\n",
    "   1. https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8bb8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
